{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part Three: Training Models </h2>\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    train_df, val_df = sklearn.model_selection.train_test_split(df, test_size=0.2)\n",
    "    return train_df, val_df\n",
    "\n",
    "#Split the data into a training set, and test set \n",
    "def accuracy(pred, actual):\n",
    "    return np.mean(pred == actual)\n",
    "# Calculate the accuracy percentage of the predicted values\n",
    "def separate_features(df):\n",
    "    feature_df = df.iloc[:,2:]\n",
    "    labels_df = df.iloc[:,1]\n",
    "    return feature_df, labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_hdf('training_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Train models using all of the following methods below. Be sure to drop the actual image column, and the encoding</h3>\tTake note of the differences in accuracy, and methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(training_data)\n",
    "X_train, y_train = separate_features(train)\n",
    "X_train.reset_index().drop(columns=['index'])\n",
    "y_train.reset_index().drop(columns=['index'])\n",
    "y_train = y_train.astype('int')\n",
    "\n",
    "X_val, y_val = separate_features(val)\n",
    "X_val.reset_index().drop(columns=['index'])\n",
    "y_val.reset_index().drop(columns=['index'])\n",
    "y_val = y_val.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def cross_val(model, k, feature_data, label_data):\n",
    "    \n",
    "    kf = sklearn.model_selection.KFold(n_splits = k)\n",
    "    kf.get_n_splits(feature_data)\n",
    "    \n",
    "    accuracy_scores = np.empty([k, 1])\n",
    "    model_params = [{} for i in range(feature_data.shape[1])]\n",
    "        \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(feature_data)):\n",
    "        model.fit(feature_data.iloc[train_index], label_data.iloc[train_index])\n",
    "        label_predict = model.predict(feature_data.iloc[test_index])\n",
    "        accuracy_scores[i] = accuracy(label_data.iloc[test_index], label_predict)\n",
    "        model_params[i] = model.get_params()\n",
    "        print(accuracy_scores[i])\n",
    "    \n",
    "    return model_params, accuracy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.39166667]\n",
      "[ 0.375]\n",
      "[ 0.38333333]\n",
      "[ 0.325]\n",
      "[ 0.35833333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lreg = LogisticRegression(random_state=0, penalty='l2', C=1)\n",
    "params = {'C': [1e-1, 1, 10, 100]}\n",
    "lreg = GridSearchCV(lreg, params, cv=5)\n",
    "model_params, accuracy_scores = cross_val(lreg, 5, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "params = {'n_neighbors': [1,2,4,8], 'algorithm': ['ball_tree', 'kd_tree']}\n",
    "neigh = KNeighborsClassifier()\n",
    "grid_neigh = GridSearchCV(neigh, params, cv=5)\n",
    "grid_neigh.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4125]\n",
      "[ 0.35]\n",
      "[ 0.43333333]\n",
      "[ 0.32916667]\n",
      "[ 0.35416667]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rand_forest = RandomForestClassifier(\n",
    "    random_state=0, \n",
    "    n_estimators=25, \n",
    "    max_depth=5, \n",
    "    bootstrap=True\n",
    ")\n",
    "params = {\n",
    "    'n_estimators': [25,75,150],\n",
    "    'max_depth': [10,20,80]\n",
    "}\n",
    "grid_rand_forest = GridSearchCV(rand_forest, params, cv=5)\n",
    "model_params, accuracy_scores = cross_val(grid_rand_forest, 5, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4]\n",
      "[ 0.33333333]\n",
      "[ 0.425]\n",
      "[ 0.32083333]\n",
      "[ 0.3625]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31893687707641194"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(\n",
    "    random_state=0, \n",
    "    n_estimators=100, \n",
    "    max_depth=20, \n",
    "    bootstrap=True\n",
    ")\n",
    "\n",
    "cross_val(rand_forest, 5, X_train, y_train)\n",
    "y_hat = rand_forest.predict(X_val)\n",
    "accuracy(y_hat, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "params = {'C': [1e-1, 1, 10, 100], 'loss': ['hinge', 'squared_hinge']}\n",
    "one_vs_one_svm = OneVsOneClassifier(LinearSVC(random_state=0, penalty='l2', C='1'))\n",
    "# grid_ovo_svm = GridSearchCV(one_vs_one_svm, params, cv=5)\n",
    "# grid_ovo_svm.fit(X_train, y_train);\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "# params = {'C': [1e-1, 1, 10, 100], 'loss': ['hinge', 'squared_hinge']}\n",
    "# grid_svm = GridSearchCV(LinearSVC(), params, cv=5)\n",
    "# grid_svm.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "# params = {'C': [1e-1, 1, 10, 100], 'loss': ['hinge', 'squared_hinge']}\n",
    "# one_vs_rest_svm = OneVsRestClassifier(LinearSVC(random_state=0, penalty='l2'))\n",
    "# grid_ovr_svm = GridSearchCV(one_vs_rest_svm, params, cv=5)\n",
    "# grid_ovr_svm.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.3289036544850498\n",
      "K-NN                Accuracy: 0.20930232558139536\n",
      "Random Forest       Accuracy: 0.31893687707641194\n",
      "SVM                 Accuracy: 0.17275747508305647\n"
     ]
    }
   ],
   "source": [
    "models = [lreg, grid_neigh, rand_forest, grid_svm]\n",
    "names = ['Logistic Regression', 'K-NN', 'Random Forest', 'SVM']\n",
    "max_name_length = len(max(names, key=len))\n",
    "\n",
    "for model, name in zip(models, names):\n",
    "    y_hat = model.predict(X_val)\n",
    "    acc = accuracy(y_hat, y_val)\n",
    "    print('{:19s} Accuracy: {}'.format(name, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
